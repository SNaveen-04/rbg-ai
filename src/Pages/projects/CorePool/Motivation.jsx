const Motivation = () => {
  return (
    <div className="p-8 tracking-wide bg-slate-100 text-Primary">
    <h1 className="text-4xl my-4">Motivation</h1>
    <p className="max-md:text-sm md:text-xl">
    when deep learning models replaced conventional methods the successive results were obtained with the strength of non-linearity learning capability through various algorithms like DNN, DAE, CNN, RNN, and LSTM. Since these algorithms are data-hungry models, only very few resource-rich languages such as English, Ancient Greek, Latin, and Egyptian Language have a larger corpus to accommodate the deep learning algorithms. This is a big constraint for resource-poor languages in the speech domain where the data is limited. Deploying deep learning-based applications for low-resource languages often suffers from data scarcity resulting in poor performance of the model. Data scarcity occurs when there is not sufficient supervised and unsupervised data for the model to train. By observing these, we have developed the CoRePooL corpus, which includes 420 minutes of annotated and 968 minutes of unannotated Baduga corpus for performing 4 speech analytics and 1 text analytics task. Badaga language is one of the low-resource languages from the Dravidian language family, predominantly used by Badagas. It is closely related to Kannada, commonly spoken by the Badaga people of the Nilgiris district at the junction of Kerala, Karnataka, and Tamilnadu. There are almost 400 villages in the Nilgiris district, where the people speak the Badaga language. According to the 2011 census, there are 134000 native Badaga speakers and according to “Times of India” there are around 2.5 lakhs of native speakers.
    </p>
    </div>
  )
}

export default Motivation